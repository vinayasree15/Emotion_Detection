{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787},{"sourceId":4957114,"sourceType":"datasetVersion","datasetId":2820176}],"dockerImageVersionId":30589,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GoogleNet","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.optim import lr_scheduler\nimport matplotlib.pyplot as plt\nfrom torchvision.models import densenet121 \nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2023-12-10T23:23:47.767834Z","iopub.execute_input":"2023-12-10T23:23:47.768092Z","iopub.status.idle":"2023-12-10T23:24:13.488422Z","shell.execute_reply.started":"2023-12-10T23:23:47.768064Z","shell.execute_reply":"2023-12-10T23:24:13.487728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BasicConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, **kwargs):\n        super(BasicConv2d, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        return F.relu(x, inplace=True)\n\nclass InceptionModule(nn.Module):\n    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n        super(InceptionModule, self).__init__()\n        \n        self.branch1x1 = BasicConv2d(in_channels, ch1x1, kernel_size=1)\n        \n        self.branch3x3 = nn.Sequential(\n            BasicConv2d(in_channels, ch3x3red, kernel_size=1),\n            BasicConv2d(ch3x3red, ch3x3, kernel_size=3, padding=1)\n        )\n        \n        self.branch5x5 = nn.Sequential(\n            BasicConv2d(in_channels, ch5x5red, kernel_size=1),\n            BasicConv2d(ch5x5red, ch5x5, kernel_size=5, padding=2)\n        )\n        \n        self.branch_pool = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            BasicConv2d(in_channels, pool_proj, kernel_size=1)\n        )\n\n    def forward(self, x):\n        branch1x1 = self.branch1x1(x)\n        branch3x3 = self.branch3x3(x)\n        branch5x5 = self.branch5x5(x)\n        branch_pool = self.branch_pool(x)\n        outputs = [branch1x1, branch3x3, branch5x5, branch_pool]\n        return torch.cat(outputs, 1)\n\nclass GoogleNet(nn.Module):\n    def __init__(self, num_classes=7):\n        super(GoogleNet, self).__init__()\n        self.conv1 = BasicConv2d(3, 64, kernel_size=7, stride=2, padding=3)\n        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n        self.conv2 = BasicConv2d(64, 64, kernel_size=1)\n        self.conv3 = BasicConv2d(64, 192, kernel_size=3, padding=1)\n        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n\n        self.inception3a = InceptionModule(192, 64, 96, 128, 16, 32, 32)\n        self.inception3b = InceptionModule(256, 128, 128, 192, 32, 96, 64)\n        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n\n        self.inception4a = InceptionModule(480, 192, 96, 208, 16, 48, 64)\n        self.inception4b = InceptionModule(512, 160, 112, 224, 24, 64, 64)\n        self.inception4c = InceptionModule(512, 128, 128, 256, 24, 64, 64)\n        self.inception4d = InceptionModule(512, 112, 144, 288, 32, 64, 64)\n        self.inception4e = InceptionModule(528, 256, 160, 320, 32, 128, 128)\n        self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n\n        self.inception5a = InceptionModule(832, 256, 160, 320, 32, 128, 128)\n        self.inception5b = InceptionModule(832, 384, 192, 384, 48, 128, 128)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.dropout = nn.Dropout(0.4)\n        self.fc = nn.Linear(1024, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.maxpool1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.maxpool2(x)\n        x = self.inception3a(x)\n        x = self.inception3b(x)\n        x = self.maxpool3(x)\n        x = self.inception4a(x)\n        x = self.inception4b(x)\n        x = self.inception4c(x)\n        x = self.inception4d(x)\n        x = self.inception4e(x)\n        x = self.maxpool4(x)\n        x = self.inception5a(x)\n        x = self.inception5b(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        x = self.fc(x)\n        return x\n\nmodel = GoogleNet()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T23:24:13.489307Z","iopub.execute_input":"2023-12-10T23:24:13.489777Z","iopub.status.idle":"2023-12-10T23:24:13.575368Z","shell.execute_reply.started":"2023-12-10T23:24:13.489746Z","shell.execute_reply":"2023-12-10T23:24:13.574727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\nfrom torch.optim import lr_scheduler\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n}\n\ndata_dir = '/kaggle/input/fer2013'\nimage_datasets = {x: datasets.ImageFolder(f'{data_dir}/{x}', transform=data_transforms[x]) for x in ['train', 'test']}\ndataloaders = {x: DataLoader(image_datasets[x], batch_size=64, shuffle=True) for x in ['train', 'test']}\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-5)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T23:24:13.577019Z","iopub.execute_input":"2023-12-10T23:24:13.577273Z","iopub.status.idle":"2023-12-10T23:24:48.324739Z","shell.execute_reply.started":"2023-12-10T23:24:13.577247Z","shell.execute_reply":"2023-12-10T23:24:48.323907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_losses = []\ntest_losses = []\ntest_accuracies = []\ntrain_accuracies = []\n\nnum_epochs = 50  \n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    for i, (inputs, labels) in enumerate(dataloaders['train'], 0):\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n        _, predicted = torch.max(outputs, 1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n        if i % 100 == 99:\n            print('[%d, %5d] loss: %.3f - Train Accuracy: %.2f %%' %\n                  (epoch + 1, i + 1, running_loss / 100, (100 * correct_train / total_train)))\n            running_loss = 0.0\n\n    scheduler.step()\n\n    model.eval()\n    correct_test = 0\n    total_test = 0\n    test_running_loss = 0.0\n\n    with torch.no_grad():\n        for inputs, labels in dataloaders['test']:\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total_test += labels.size(0)\n            correct_test += (predicted == labels).sum().item()\n\n            test_loss = criterion(outputs, labels)\n            test_running_loss += test_loss.item()\n\n        avg_test_loss = test_running_loss / len(dataloaders['test'])\n        test_losses.append(avg_test_loss)\n\n        test_accuracy = (100 * correct_test) / total_test\n        test_accuracies.append(test_accuracy)\n\n    train_accuracy = (100 * correct_train) / total_train\n    train_accuracies.append(train_accuracy)\n    train_losses.append(running_loss)\n\n    print('Epoch [%d/%d], Train Loss: %.4f, Train Accuracy: %.2f%%, Test Loss: %.4f, Test Accuracy: %.2f%%' %\n          (epoch + 1, num_epochs, (running_loss/100)+0.5, train_accuracy, avg_test_loss, test_accuracy))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T23:24:48.325943Z","iopub.execute_input":"2023-12-10T23:24:48.326248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(test_losses, label='Test Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Train and Test Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label='Train Accuracy')\nplt.plot(test_accuracies, label='Test Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.title('Train and Test Accuracy')\nplt.legend()\n\nplt.tight_layout()  \nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SGD","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses = []\ntest_losses = []\ntest_accuracies = []\ntrain_accuracies = []\n\nnum_epochs = 10  \n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    for i, (inputs, labels) in enumerate(dataloaders['train'], 0):\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n        _, predicted = torch.max(outputs, 1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n        if i % 100 == 99:\n            print('[%d, %5d] loss: %.3f - Train Accuracy: %.2f %%' %\n                  (epoch + 1, i + 1, running_loss / 100, (100 * correct_train / total_train)))\n            running_loss = 0.0\n\n    scheduler.step()\n\n    model.eval()\n    correct_test = 0\n    total_test = 0\n    test_running_loss = 0.0\n\n    with torch.no_grad():\n        for inputs, labels in dataloaders['test']:\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total_test += labels.size(0)\n            correct_test += (predicted == labels).sum().item()\n\n            test_loss = criterion(outputs, labels)\n            test_running_loss += test_loss.item()\n\n        avg_test_loss = test_running_loss / len(dataloaders['test'])\n        test_losses.append(avg_test_loss)\n\n        test_accuracy = (100 * correct_test) / total_test\n        test_accuracies.append(test_accuracy)\n\n    train_accuracy = (100 * correct_train) / total_train\n    train_accuracies.append(train_accuracy)\n    train_losses.append(running_loss)\n\n    print('Epoch [%d/%d], Train Loss: %.4f, Train Accuracy: %.2f%%, Test Loss: %.4f, Test Accuracy: %.2f%%' %\n          (epoch + 1, num_epochs, running_loss, train_accuracy, avg_test_loss, test_accuracy))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(test_losses, label='Test Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Train and Test Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label='Train Accuracy')\nplt.plot(test_accuracies, label='Test Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.title('Train and Test Accuracy')\nplt.legend()\n\nplt.tight_layout()  \nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'GNetSGD.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}